{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word detection system\n",
    "## (THIS CODE IS NOT COMPLETE)\n",
    "\n",
    "### This project uses a large amount of the code found [here](https://mlblr.com/includes/mlai/index.html#yolov2) which describes in detail how YOLOv2 works.\n",
    "\n",
    "This notebook contains all the code necessary for creating and training a convolutional word detection network similar to the YOLO network used to detect physical objects. This notebook uses images as training data along with their associated annotation files which contain bounding box information. The tool I used to annotate my images can be found on my github [here](https://github.com/bradylowe/word-detection-with-conv-net.git)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary packages\n",
    "\n",
    "You will certainly want the GPU version of tensorflow running to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Image processing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "\n",
    "# Machine learning\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Gauge performance\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some project configuration constants\n",
    "\n",
    "Here, we make some choices about the overall project. These choices \n",
    "will determine the exact functionality of the computation graph \n",
    "we will create and train. \n",
    "\n",
    "First of all, we need to define the classes we will be trying to detect.\n",
    "\n",
    "The image height and width set here are chosen because we are expecting\n",
    "text documents of size 8.5\" x 11\". The ANCHORS variable stores the width\n",
    "and height of the anchor boxes \\[width1, height1, width2, height2, ...\\].\n",
    "The threshold variables are for determining which boxes have positive\n",
    "detections.\n",
    "\n",
    "The scale variables are for determining which predictions are the most important\n",
    "to get right during training. These weights scale individual terms in the \n",
    "custom loss function defined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['section', 'header', 'word', 'bullet', 'page']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 800 / 2, 620 / 2\n",
    "GRID_H,  GRID_W  = 13 , 10\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "BOX              = len(ANCHORS) // 2\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "The dataset needed for training a detection network consists of:\n",
    " - Bare training images containing words to detect \n",
    " - List of bounding boxes which label each object in the image\n",
    "   * Need top-left corner (xmin, ymin)\n",
    "   * Need bottom-right corner (xmax, ymax)\n",
    "   * Need class contained in box\n",
    "   * box ==>  \\[xmin, ymin, xmax, ymax, cls0, cls1, cls2, cls3, cls4\\] where \n",
    "     cls( j ) = 1 if this box bounds the j^th class, else 0\n",
    "   \n",
    "### (Note about pre-training)\n",
    "Some pre-training will need to be performed on most of the network. \n",
    "This is because of the large number of predictions made in the network.\n",
    "First, we will train many layers of the network on simple classification.\n",
    "This means that we will need some images in the dataset that do not contain words.\n",
    "Pre-training on classification will make detection training much faster and easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_from_label(label):\n",
    "    cur_class = LABELS.index(label)\n",
    "    class_vec = np.zeros(CLASS, dtype=\"float\")\n",
    "    class_vec[cur_class] = 1.\n",
    "    return class_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_boxes_for_image(im_path):\n",
    "    \"\"\" \n",
    "    Load all the boxes defined in the xml_file sent in.\n",
    "    A box consists of [class, top_left_corner, bottom_right_corner, parent_grid_cell].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate xml path from given path\n",
    "    xml_path = os.path.splitext(im_path)[0] + '.xml'\n",
    "    \n",
    "    # Read lines from file\n",
    "    with open(xml_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # Grab image dimensions\n",
    "    width = int(lines[4].strip()[7:-8])\n",
    "    height = int(lines[5].strip()[8:-9])\n",
    "    \n",
    "    # Read info from boxes\n",
    "    boxes = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        \n",
    "        if '<object>' in line:\n",
    "            box = np.zeros(4 + CLASS, dtype=\"float\")\n",
    "            \n",
    "            xmin = int(lines[idx + 7].strip()[6:-7])\n",
    "            ymin = int(lines[idx + 8].strip()[6:-7])\n",
    "            xmax = int(lines[idx + 9].strip()[6:-7])\n",
    "            ymax = int(lines[idx + 10].strip()[6:-7])\n",
    "            box[0:4] = [xmin, ymin, xmax, ymax]\n",
    "            \n",
    "            label = lines[idx + 1].strip()[6:-7]\n",
    "            box[4:] = get_one_hot_from_label(label)\n",
    "            \n",
    "            boxes.append(box)\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_images_and_boxes(im_dir, max_examples=None):\n",
    "    \n",
    "    images = []\n",
    "    images_with_boxes = []\n",
    "    boxes = []\n",
    "    \n",
    "    for im_path in os.listdir(im_dir):\n",
    "        \n",
    "        # Define paths to image and xml files\n",
    "        im_path_boxes = os.splitext(im_path)[0] + '_boxes' + os.splitext(im_path)[1]\n",
    "        \n",
    "        im_path = os.path.join(im_dir, im_path)\n",
    "        im_path_boxes = os.path.join(im_dir, im_path_boxes)\n",
    "        \n",
    "        # Load data\n",
    "        images.append(misc.imread(im_path))\n",
    "        images_with_boxes.append(misc.imread(im_path_boxes))\n",
    "        boxes = load_boxes_for_image(im_path)\n",
    "        \n",
    "        if max_examples is not None and len(images) >= max_examples:\n",
    "            break\n",
    "        \n",
    "    return images, images_with_boxes, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(data, batch_size=64):\n",
    "    max_index = min(batch_size, len(data))\n",
    "    perm_idx = np.random.permutation(max_index)\n",
    "    return [data[perm_idx[idx]] for idx in range(max_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some images using helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image(image pixels, boxes=None)\n",
    "# print_boxes(boxes)\n",
    "# print_box_stats(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for the network computations\n",
    "\n",
    "Neural networks are complex things with many degrees of freedom. There are a few functions that we must perform repeatedly that take many inputs. With helper functions, we can hard-code some things and reduce the number of inputs to make the problem easier to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(layer, num_inputs, num_outputs, use_relu=True):\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.leaky_relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True,\n",
    "                   use_batch_norm=True):  # Use 2x2 max-pooling.\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    #biases = new_biases(length=num_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    #layer += biases\n",
    "    \n",
    "    if use_batch_norm:\n",
    "        layer = tf.nn.batch_noralization(input)\n",
    "    \n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    layer = tf.nn.leaky_relu(layer)\n",
    "    \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(image, new_scale):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow input and output (architecture)\n",
    "\n",
    "We need to now create the Tensorflow variables and graph. This included placeholders for the inputs (images array and one-hot labels array), as well as a computation we want performed (the network). \n",
    "\n",
    " - The input image placeholder is called x_image\n",
    " - The input labels placeholder is called y_true\n",
    " - The final output computation is called y_pred\n",
    "    * y_pred is the arg max of the final output activations from the softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.placeholder(tf.float32, shape=[None, IMAGE_H, IMAGE_W, 1], name='input_image')\n",
    "true_boxes  = tf.placeholder(tf.float32, shape=[None, 1, 1, 1, TRUE_BOX_BUFFER, 4], name='true_boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo model (greyscale)\n",
    "\n",
    "# 1 - 5\n",
    "x, _ = new_conv_layer(input_image, 1, 3, 32)\n",
    "x, _ = new_conv_layer(x, 32, 3, 64)\n",
    "x, _ = new_conv_layer(x, 64, 3, 128, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 128, 1, 64, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 64, 3, 128)\n",
    "\n",
    "# 6 - 10\n",
    "x, _ = new_conv_layer(x, 128, 3, 256, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 256, 1, 128, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 128, 3, 256)\n",
    "x, _ = new_conv_layer(x, 256, 3, 512, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 512, 1, 256, use_pooling=False)\n",
    "\n",
    "# 11 - 15\n",
    "x, _ = new_conv_layer(x, 256, 3, 512, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 512, 1, 256, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 256, 3, 512, use_pooling=False)\n",
    "skip_con = x\n",
    "x, _ = new_conv_layer(x, 512, 3, 1024, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 1024, 1, 512, use_pooling=False)\n",
    "\n",
    "# 16 - 20\n",
    "x, _ = new_conv_layer(x, 512, 3, 1024, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 1024, 1, 512, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 512, 3, 1024, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 1024, 3, 1024, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 1024, 3, 1024, use_pooling=False)\n",
    "\n",
    "# 21\n",
    "skip_con = new_conv_layer(skip_con, 512, 1, 64, use_pooling=False)\n",
    "skip_con = space_to_depth_2x(skip_con)\n",
    "x = concatenate([skip_con, x])\n",
    "\n",
    "# 22 - 23\n",
    "x, _ = new_conv_layer(x, 1280, 3, 1024, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 1024, 1, BOX * (5 + CLASS), use_pooling=False)\n",
    "\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "\n",
    "#y_pred = tf.nn.softmax(layer_fc2)\n",
    "#y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 5\n",
    "x, _ = new_conv_layer(input_image, 1, 3, 32)\n",
    "x, _ = new_conv_layer(x, 32, 3, 64)\n",
    "x, _ = new_conv_layer(x, 64, 3, 128, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 128, 1, 64, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 64, 3, 128)\n",
    "skip_con = x\n",
    "\n",
    "# 6 - 10\n",
    "x, _ = new_conv_layer(x, 128, 3, 256, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 256, 1, 128, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 128, 3, 256)\n",
    "x, _ = new_conv_layer(x, 256, 3, 512, use_pooling=False)\n",
    "x, _ = new_conv_layer(x, 512, 1, 256, use_pooling=False)\n",
    "\n",
    "# 11\n",
    "skip_con = new_conv_layer(skip_con, 128, 1, 64, use_pooling=False)\n",
    "skip_con = space_to_depth_2x(skip_con)\n",
    "x = concatenate([skip_con, x])\n",
    "\n",
    "# 12\n",
    "x, _ = new_conv_layer(x, 512, 3, 512, use_pooling=False)\n",
    "\n",
    "\n",
    "x, x_dim = flatten_layer(x)\n",
    "x = new_fc_layer(x, x_dim, 128)\n",
    "x = new_fc_layer(x, 128, CLASS, False)\n",
    "\n",
    "y = tf.nn.softmax(x)\n",
    "y_cls = tf.argmax(y, axis=1)\n",
    "\n",
    "\n",
    "#x, _ = new_conv_layer(x, 512, 1, BOX * (5 + CLASS), use_pooling=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "\n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "\n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "\n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "\n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "\n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "\n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "\n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "\n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "\n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "\n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half\n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "\n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "\n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "\n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "\n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half\n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "\n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "\n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE\n",
    "\n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES),\n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask,\n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask,\n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy,\n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "\n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "\n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "\n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "\n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    \"\"\"\n",
    "    Debugging code\n",
    "    \"\"\"\n",
    "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "    total_recall = tf.assign_add(total_recall, current_recall)\n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-3c016caf98ee>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}\n",
    "\n",
    "train_imgs, seen_train_labels = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('train_imgs', 'wb') as fp:\n",
    "#    pickle.dump(train_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('train_imgs', 'rb') as fp:\n",
    "#    train_imgs = pickle.load(fp)\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(valid_annot_folder, valid_image_folder, labels=LABELS)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('valid_imgs', 'wb') as fp:\n",
    "#    pickle.dump(valid_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('valid_imgs', 'rb') as fp:\n",
    "#    valid_imgs = pickle.load(fp)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)\n",
    "tb_counter  = len([log for log in os.listdir(os.path.expanduser('~/logs/')) if 'coco_' in log]) + 1\n",
    "tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/') + 'coco_' + '_' + str(tb_counter), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_images=False)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_coco.h5\")\n",
    "\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "image = cv2.imread('images/giraffe.jpg')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "input_image = cv2.resize(image, (416, 416))\n",
    "input_image = input_image / 255.\n",
    "input_image = input_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "netout = model.predict([input_image, dummy_array])\n",
    "\n",
    "boxes = decode_netout(netout[0], \n",
    "                      obj_threshold=OBJ_THRESHOLD,\n",
    "                      nms_threshold=NMS_THRESHOLD,\n",
    "                      anchors=ANCHORS, \n",
    "                      nb_class=CLASS)\n",
    "image = draw_boxes(image, boxes, labels=LABELS)\n",
    "\n",
    "plt.imshow(image[:,:,::-1]); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Tensorflow session\n",
    "\n",
    "Tensorflow is not doing anything yet. We have created some Tensorflow structures, but no computuation has been performed. We were just at the drawing board having a discussion.\n",
    "\n",
    "Now, let's fire up the Tensorflow computation engine, initialize all the variables we had \"discussed\" before, and perform the planned computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More helper functions for optimization, evaluation, and printing\n",
    "\n",
    "Now that we have a \"session\" defined and running, we will write a couple more helper functions that use a reference to that session. These helper functions will actually call on tensorflow to compute predictions given input (and sometimes, perform optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch, _ = \\\n",
    "            get_random_batch(train_images, train_labels, train_batch_size)\n",
    "        feed_dict_train = {x_image: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i + 1, acc))\n",
    "            \n",
    "            \n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights using the optimizer\n",
    "\n",
    "The job of the optimizer is to optimize the value of the weights in each layer so that the computation graph results in the correct label for the given input.\n",
    "\n",
    "Run the optimizer for some number of iteration. The model learns very quickly (under 100 iterations) how to correctly classify images at least 80% of the time. It takes a bit longer (over 1,000 iterations) to drive that accuracy up to 98%. \n",
    "\n",
    "Optimizing the hyper-parameters (changing model architecture, optimiziation algorithm, using regularization, changing data input, etc.) can help get the accuracy above 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:    301, Training Accuracy:  96.9%\n",
      "Optimization Iteration:    401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:    501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:    601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:    701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:    801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:    901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1101, Training Accuracy: 100.0%\n",
      "Time usage: 0:00:28\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    Runs the graph stored in \"sess\" to predict boxes for \"image_file\". Prints and plots the preditions.\n",
    "    \n",
    "    Arguments:\n",
    "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
    "    image_file -- name of an image stored in the \"images\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
    "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
    "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
    "    \n",
    "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
    "    # You'll need to use feed_dict={yolo_model.input: ... , K.learning_phase(): 0})\n",
    "    ### START CODE HERE ### (â‰ˆ 1 line)\n",
    "    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict={yolo_model.input: image_data, K.learning_phase(): 0})\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # Display the results in the notebook\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "    \n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-830149a6863a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
